<?xml version="1.0" encoding="UTF-8"?>
<configuration>
<property>
<name>ipc.server.tcpnodelay</name>
<value>true</value>
</property>
<property>
<name>iostat.interval</name>
<value>600</value>
</property>
<property>
<name>dfs.client.https.need-auth</name>
<value>false</value>
</property>
<property>
<name>dfs.replication</name>
<value>3</value>
</property>
<property>
<name>dfs.ha.fencing.ssh.private-key-files</name>
<value>/home/omm/.ssh/id_rsa</value>
</property>
<property>
<name>dfs.namenode.audit.log.async</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.kerberos.https.principal</name>
<value>hdfs/hadoop.hadoop_b.com@HADOOP_B.COM</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.session-timeout.ms</name>
<value>45000</value>
</property>
<property>
<name>ipc.server.handler.queue.size</name>
<value>100</value>
</property>
<property>
<name>dfs.namenode.journalnode</name>
<value>shyp-bigdata-b-cn05:25012;shyp-bigdata-b-cn02:25012;shyp-bigdata-b-cn04:25012;shyp-bigdata-b-cn01:25012;shyp-bigdata-b-cn03:25012</value>
</property>
<property>
<name>dfs.namenode.audit.log.debug.cmdlist</name>
<value>open,getfileinfo,listStatus,getAclStatus</value>
</property>
<property>
<name>dfs.namenode.replication.min</name>
<value>1</value>
</property>
<property>
<name>dfs.client.socketcache.expiryMsec</name>
<value>3000</value>
</property>
<property>
<name>dfs.namenode.fs-limits.min-block-size</name>
<value>1048576</value>
</property>
<property>
<name>dfs.namenode.http.policy</name>
<value>HTTPS_ONLY</value>
</property>
<property>
<name>dfs.namenode.acls.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.datanode.registration.ip-hostname-check</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.path.based.cache.block.map.allocation.percent</name>
<value>0.25f</value>
</property>
<property>
<name>dfs.journalnode.kerberos.principal</name>
<value>hdfs/hadoop.hadoop_b.com@HADOOP_B.COM</value>
</property>
<property>
<name>dfs.namenode.edits.noeditlogchannelflush</name>
<value>false</value>
</property>
<property>
<name>hadoop.proxyuser.miner.groups</name>
<value>*</value>
</property>
<property>
<name>dfs.balancer.auto.exclude.datanodes</name>
<value></value>
</property>
<property>
<name>dfs.http.policy</name>
<value>HTTPS_ONLY</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.hacluster</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>dfs.namenode.replication.interval</name>
<value>3</value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc-address.hacluster.7764</name>
<value>shyp-bigdata-b-cn06:25005</value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc-address.hacluster.7765</name>
<value>shyp-bigdata-b-cn07:25005</value>
</property>
<property>
<name>dfs.namenode.safemode.min.datanodes</name>
<value>0</value>
</property>
<property>
<name>dfs.datanode.kerberos.principal</name>
<value>hdfs/hadoop.hadoop_b.com@HADOOP_B.COM</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.lock.limit</name>
<value>10</value>
</property>
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.delegation.token.max-lifetime</name>
<value>604800000</value>
</property>
<property>
<name>dfs.auto.data.mover.cron.expression</name>
<value>0 * * * *</value>
</property>
<property>
<name>dfs.namenode.kerberos.principal</name>
<value>hdfs/hadoop.hadoop_b.com@HADOOP_B.COM</value>
</property>
<property>
<name>dfs.namenode.avoid.write.stale.datanode</name>
<value>true</value>
</property>
<property>
<name>dfs.balancer.auto.policy</name>
<value>datanode</value>
</property>
<property>
<name>ipc.25000.callqueue.impl</name>
<value>java.util.concurrent.LinkedBlockingQueue</value>
</property>
<property>
<name>dfs.namenode.num.extra.edits.retained</name>
<value>1000000</value>
</property>
<property>
<name>ipc.client.connect.max.retries.on.timeouts</name>
<value>45</value>
</property>
<property>
<name>dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction</name>
<value>0.6</value>
</property>
<property>
<name>dfs.client-write-packet-size</name>
<value>262144</value>
</property>
<property>
<name>dfs.datanode.transfer.socket.send.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>dfs.namenode.checkpoint.txns</name>
<value>1000000</value>
</property>
<property>
<name>dfs.client.block.write.retries</name>
<value>3</value>
</property>
<property>
<name>dfs.namenode.safemode.threshold-pct</name>
<value>0.999999</value>
</property>
<property>
<name>dfs.namenode.kerberos.principal.pattern</name>
<value>*</value>
</property>
<property>
<name>dfs.namenode.replication.max-streams</name>
<value>64</value>
</property>
<property>
<name>dfs.namenode.replication.considerLoad</name>
<value>true</value>
</property>
<property>
<name>dfs.nameservices</name>
<value>hacluster</value>
</property>
<property>
<name>ipc.client.idlethreshold</name>
<value>4000</value>
</property>
<property>
<name>dfs.namenode.file.close.num-committed-allowed</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.reconstruction.pending.timeout-sec</name>
<value>900</value>
</property>
<property>
<name>ipc.server.max.response.size</name>
<value>1048576</value>
</property>
<property>
<name>dfs.client.failover.connection.retries.on.timeouts</name>
<value>0</value>
</property>
<property>
<name>backup.split.size</name>
<value>1073741824</value>
</property>
<property>
<name>dfs.client.close.ack-timeout</name>
<value>900000</value>
</property>
<property>
<name>dfs.namenode.replication.work.multiplier.per.iteration</name>
<value>10</value>
</property>
<property>
<name>ipc.25000.backoff.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.image.compression.codec</name>
<value>org.apache.hadoop.io.compress.DefaultCodec</value>
</property>
<property>
<name>dfs.client.socket-timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.namenode.replication.max-streams-hard-limit</name>
<value>128</value>
</property>
<property>
<name>dfs.datanode.socket.write.timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.auto.data.mover.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.accesstime.precision</name>
<value>3600000</value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc-bind-host</name>
<value>shyp-bigdata-b-cn06</value>
</property>
<property>
<name>dfs.image.transfer.timeout</name>
<value>600000</value>
</property>
<property>
<name>ipc.25000.faircallqueue.decay-scheduler.thresholds</name>
<value></value>
</property>
<property>
<name>net.topology.nodegroup.aware</name>
<value>false</value>
</property>
<property>
<name>dfs.stream-buffer-size</name>
<value>4096</value>
</property>
<property>
<name>dfs.namenode.invalidate.work.pct.per.iteration</name>
<value>0.32</value>
</property>
<property>
<name>dfs.namenode.max.objects</name>
<value>0</value>
</property>
<property>
<name>dfs.bytes-per-checksum</name>
<value>512</value>
</property>
<property>
<name>dfs.cluster.administrators</name>
<value>hdfs supergroup,System_administrator_186</value>
</property>
<property>
<name>dfs.encrypt.data.transfer.algorithm</name>
<value>3des</value>
</property>
<property>
<name>dfs.client.read.shortcircuit</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.https.port</name>
<value>25003</value>
</property>
<property>
<name>dfs.namenode.inode.attributes.provider.class</name>
<value>com.huawei.hadoop.adapter.hdfs.plugin.HWINodeAttributeProvider</value>
</property>
<property>
<name>net.topology.impl</name>
<value>org.apache.hadoop.net.NetworkTopology</value>
</property>
<property>
<name>dfs.client.failover.sleep.base.millis</name>
<value>500</value>
</property>
<property>
<name>dfs.permissions.superusergroup</name>
<value>supergroup</value>
</property>
<property>
<name>dfs.block.replicator.classname</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy</value>
</property>
<property>
<name>dfs.namenode.fs-limits.max-directory-items</name>
<value>1048576</value>
</property>
<property>
<name>dfs.ha.log-roll.period</name>
<value>120</value>
</property>
<property>
<name>ipc.25000.faircallqueue.multiplexer.weights</name>
<value></value>
</property>
<property>
<name>dfs.namenode.io.load.balance.reading.enabled</name>
<value>false</value>
</property>
<property>
<name>dfs.client.socket.send.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>dfs.ha.namenode.id</name>
<value>7764</value>
</property>
<property>
<name>oi.dfs.colocation.file.pattern</name>
<value></value>
</property>
<property>
<name>ipc.25000.identity-provider.impl</name>
<value>org.apache.hadoop.ipc.UserIdentityProvider</value>
</property>
<property>
<name>dfs.namenode.heartbeat.recheck-interval</name>
<value>300000</value>
</property>
<property>
<name>dfs.namenode.safemode.extension</name>
<value>15000</value>
</property>
<property>
<name>dfs.client.failover.sleep.max.millis</name>
<value>15000</value>
</property>
<property>
<name>dfs.datanode.transfer.socket.recv.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>fs.permissions.umask-mode</name>
<value>022</value>
</property>
<property>
<name>audit.service.name</name>
<value>HDFS</value>
</property>
<property>
<name>dfs.namenode.fs-limits.max-blocks-per-file</name>
<value>1048576</value>
</property>
<property>
<name>ipc.25000.faircallqueue.priority-levels</name>
<value>4</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.enable</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.lifeline.handler.ratio</name>
<value>0.1</value>
</property>
<property>
<name>backup.meta.zk.acl</name>
<value>world:anyone:r,auth::cdrwa</value>
</property>
<property>
<name>dfs.balancer.auto.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.ha.zkfc.port</name>
<value>25015</value>
</property>
<property>
<name>net.topology.node.switch.mapping.impl</name>
<value>org.apache.hadoop.net.ScriptBasedMapping</value>
</property>
<property>
<name>dfs.storage.policy.enabled</name>
<value>true</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.quorum</name>
<value>shyp-bigdata-b-cn05:24002,shyp-bigdata-b-cn02:24002,shyp-bigdata-b-cn04:24002,shyp-bigdata-b-cn01:24002,shyp-bigdata-b-cn03:24002</value>
</property>
<property>
<name>backup.meta.zk.parent-znode</name>
<value>/hdfs-backup</value>
</property>
<property>
<name>dfs.namenode.http-address.hacluster.7765</name>
<value>shyp-bigdata-b-cn07:25002</value>
</property>
<property>
<name>dfs.encrypt.data.transfer.cipher.suites</name>
<value>AES/CTR/NoPadding</value>
</property>
<property>
<name>dfs.namenode.http-address.hacluster.7764</name>
<value>shyp-bigdata-b-cn06:25002</value>
</property>
<property>
<name>dfs.namenode.num.checkpoints.retained</name>
<value>3</value>
</property>
<property>
<name>dfs.nodetag.tagloader.interval</name>
<value>10000</value>
</property>
<property>
<name>dfs.blockplacement.mandatory.rackgroup.name</name>
<value></value>
</property>
<property>
<name>dfs.permissions.enabled</name>
<value>true</value>
</property>
<property>
<name>ha.zookeeper.quorum</name>
<value>shyp-bigdata-b-cn05:24002,shyp-bigdata-b-cn02:24002,shyp-bigdata-b-cn04:24002,shyp-bigdata-b-cn01:24002,shyp-bigdata-b-cn03:24002</value>
</property>
<property>
<name>dfs.rackgroup.nextpolicy</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault</value>
</property>
<property>
<name>ipc.server.read.threadpool.size</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.stale.datanode.interval</name>
<value>30000</value>
</property>
<property>
<name>dfs.balancer.auto.excluded.paths</name>
<value></value>
</property>
<property>
<name>backup.worker.implement.multi-thread.num</name>
<value>3</value>
</property>
<property>
<name>dfs.namenode.http.port</name>
<value>25002</value>
</property>
<property>
<name>dfs.client.io-weight</name>
<value>10</value>
</property>
<property>
<name>dfs.domain.socket.path</name>
<value>/var/run/FusionInsight-HDFS/dn_socket</value>
</property>
<property>
<name>dfs.namenode.handler.count</name>
<value>64</value>
</property>
<property>
<name>dfs.qjournal.write-txns.timeout.ms</name>
<value>20000</value>
</property>
<property>
<name>dfs.image.transfer.bandwidthPerSec</name>
<value>0</value>
</property>
<property>
<name>dfs.replication.max</name>
<value>512</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>/srv/BigData/namenode</value>
</property>
<property>
<name>ipc.client.kill.max</name>
<value>10</value>
</property>
<property>
<name>oi.dfs.colocation.balancer.exclude.block.policy.class</name>
<value>com.huawei.hadoop.oi.colocation.PathPatternBasedExcludeBlockPolicy</value>
</property>
<property>
<name>iostat.enabled</name>
<value>false</value>
</property>
<property>
<name>dfs.block.access.token.enable</name>
<value>true</value>
</property>
<property>
<name>dfs.blocksize</name>
<value>134217728</value>
</property>
<property>
<name>dfs.namenode.lifeline.handler.count</name>
<value></value>
</property>
<property>
<name>dfs.balancer.auto.threshold</name>
<value>10</value>
</property>
<property>
<name>dfs.encrypt.data.transfer</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.write.stale.datanode.ratio</name>
<value>0.5f</value>
</property>
<property>
<name>dfs.client.failover.max.attempts</name>
<value>10</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.replication</name>
<value>2</value>
</property>
<property>
<name>dfs.journalnode.kerberos.internal.spnego.principal</name>
<value>HTTP/_HOST@HADOOP_B.COM</value>
</property>
<property>
<name>dfs.hosts</name>
<value></value>
</property>
<property>
<name>dfs.client.read.shortcircuit.skip.checksum</name>
<value>true</value>
</property>
<property>
<name>dfs.nameservices.mappings</name>
<value>[{"name":"hacluster","roleInstances":["7764","7765"]}]</value>
</property>
<property>
<name>dfs.client.file-block-storage-locations.timeout.millis</name>
<value>600000</value>
</property>
<property>
<name>backup.meta.zk.quorum</name>
<value>shyp-bigdata-b-cn05:24002,shyp-bigdata-b-cn02:24002,shyp-bigdata-b-cn04:24002,shyp-bigdata-b-cn01:24002,shyp-bigdata-b-cn03:24002</value>
</property>
<property>
<name>dfs.balancer.auto.include.datanodes</name>
<value></value>
</property>
<property>
<name>dfs.namenode.delegation.token.renew-interval</name>
<value>86400000</value>
</property>
<property>
<name>dfs.namenode.retrycache.heap.percent</name>
<value>0.03f</value>
</property>
<property>
<name>dfs.image.loader.thread</name>
<value>0</value>
</property>
<property>
<name>dfs.web.authentication.kerberos.principal</name>
<value>HTTP/_HOST@HADOOP_B.COM</value>
</property>
<property>
<name>hadoop.http.authentication.cookie.domain</name>
<value></value>
</property>
<property>
<name>dfs.namenode.kerberos.internal.spnego.principal</name>
<value>HTTP/_HOST@HADOOP_B.COM</value>
</property>
<property>
<name>dfs.image.compress</name>
<value>false</value>
</property>
<property>
<name>dfs.client.failover.connection.retries</name>
<value>0</value>
</property>
<property>
<name>dfs.namenode.plugins</name>
<value></value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc.port</name>
<value>25005</value>
</property>
<property>
<name>dfs.namenode.checkpoint.check.period</name>
<value>60</value>
</property>
<property>
<name>dfs.federation.datanode</name>
<value>shyp-bigdata-b-dn073:25008,shyp-bigdata-b-dn072:25008,shyp-bigdata-b-dn070:25008,shyp-bigdata-b-dn069:25008,shyp-bigdata-b-dn067:25008,shyp-bigdata-b-dn055:25008,shyp-bigdata-b-dn054:25008,shyp-bigdata-b-dn053:25008,shyp-bigdata-b-dn052:25008,shyp-bigdata-b-dn051:25008,shyp-bigdata-b-dn050:25008,shyp-bigdata-b-dn049:25008,shyp-bigdata-b-dn048:25008,shyp-bigdata-b-dn047:25008,shyp-bigdata-b-dn056:25008,shyp-bigdata-b-dn068:25008,shyp-bigdata-b-dn080:25008,shyp-bigdata-b-dn128:25008,shyp-bigdata-b-dn066:25008,shyp-bigdata-b-dn065:25008,shyp-bigdata-b-dn064:25008,shyp-bigdata-b-dn169:25008,shyp-bigdata-b-dn168:25008,shyp-bigdata-b-dn167:25008,shyp-bigdata-b-dn166:25008,shyp-bigdata-b-dn165:25008,shyp-bigdata-b-dn164:25008,shyp-bigdata-b-dn163:25008,shyp-bigdata-b-dn162:25008,shyp-bigdata-b-dn161:25008,shyp-bigdata-b-dn160:25008,shyp-bigdata-b-dn159:25008,shyp-bigdata-b-dn158:25008,shyp-bigdata-b-dn157:25008,shyp-bigdata-b-dn156:25008,shyp-bigdata-b-dn155:25008,shyp-bigdata-b-dn154:25008,shyp-bigdata-b-dn153:25008,shyp-bigdata-b-dn152:25008,shyp-bigdata-b-dn151:25008,shyp-bigdata-b-dn150:25008,shyp-bigdata-b-dn149:25008,shyp-bigdata-b-dn148:25008,shyp-bigdata-b-dn147:25008,shyp-bigdata-b-dn146:25008,shyp-bigdata-b-dn145:25008,shyp-bigdata-b-dn144:25008,shyp-bigdata-b-dn143:25008,shyp-bigdata-b-dn142:25008,shyp-bigdata-b-dn141:25008,shyp-bigdata-b-dn140:25008,shyp-bigdata-b-dn139:25008,shyp-bigdata-b-dn138:25008,shyp-bigdata-b-dn137:25008,shyp-bigdata-b-dn045:25008,shyp-bigdata-b-dn044:25008,shyp-bigdata-b-dn043:25008,shyp-bigdata-b-dn042:25008,shyp-bigdata-b-dn040:25008,shyp-bigdata-b-dn039:25008,shyp-bigdata-b-dn038:25008,shyp-bigdata-b-dn046:25008,shyp-bigdata-b-dn112:25008,shyp-bigdata-b-dn033:25008,shyp-bigdata-b-dn035:25008,shyp-bigdata-b-dn034:25008,shyp-bigdata-b-dn032:25008,shyp-bigdata-b-dn030:25008,shyp-bigdata-b-dn037:25008,shyp-bigdata-b-dn107:25008,shyp-bigdata-b-dn027:25008,shyp-bigdata-b-dn026:25008,shyp-bigdata-b-dn025:25008,shyp-bigdata-b-dn103:25008,shyp-bigdata-b-dn021:25008,shyp-bigdata-b-dn020:25008,shyp-bigdata-b-dn019:25008,shyp-bigdata-b-dn018:25008,shyp-bigdata-b-dn017:25008,shyp-bigdata-b-dn100:25008,shyp-bigdata-b-dn015:25008,shyp-bigdata-b-dn014:25008,shyp-bigdata-b-dn013:25008,shyp-bigdata-b-dn012:25008,shyp-bigdata-b-dn124:25008,shyp-bigdata-b-dn125:25008,shyp-bigdata-b-dn126:25008,shyp-bigdata-b-dn130:25008,shyp-bigdata-b-dn133:25008,shyp-bigdata-b-dn134:25008,shyp-bigdata-b-dn023:25008,shyp-bigdata-b-dn005:25008,shyp-bigdata-b-dn079:25008,shyp-bigdata-b-dn041:25008,shyp-bigdata-b-dn036:25008,shyp-bigdata-b-dn031:25008,shyp-bigdata-b-dn029:25008,shyp-bigdata-b-dn028:25008,shyp-bigdata-b-dn024:25008,shyp-bigdata-b-dn106:25008,shyp-bigdata-b-dn114:25008,shyp-bigdata-b-dn117:25008,shyp-bigdata-b-dn118:25008,shyp-bigdata-b-dn119:25008,shyp-bigdata-b-dn122:25008,shyp-bigdata-b-dn123:25008,shyp-bigdata-b-dn063:25008,shyp-bigdata-b-dn007:25008,shyp-bigdata-b-dn011:25008,shyp-bigdata-b-dn002:25008,shyp-bigdata-b-dn003:25008,shyp-bigdata-b-dn091:25008,shyp-bigdata-b-dn001:25008,shyp-bigdata-b-dn090:25008,shyp-bigdata-b-dn108:25008,shyp-bigdata-b-dn111:25008,shyp-bigdata-b-dn136:25008,shyp-bigdata-b-dn131:25008,shyp-bigdata-b-dn129:25008,shyp-bigdata-b-dn127:25008,shyp-bigdata-b-dn132:25008,shyp-bigdata-b-dn121:25008,shyp-bigdata-b-dn120:25008,shyp-bigdata-b-dn116:25008,shyp-bigdata-b-dn115:25008,shyp-bigdata-b-dn113:25008,shyp-bigdata-b-dn109:25008,shyp-bigdata-b-dn110:25008,shyp-bigdata-b-dn022:25008,shyp-bigdata-b-dn009:25008,shyp-bigdata-b-dn010:25008,shyp-bigdata-b-dn008:25008,shyp-bigdata-b-dn094:25008,shyp-bigdata-b-dn004:25008,shyp-bigdata-b-dn006:25008,shyp-bigdata-b-dn092:25008,shyp-bigdata-b-dn016:25008,shyp-bigdata-b-dn097:25008,shyp-bigdata-b-dn059:25008,shyp-bigdata-b-dn071:25008,shyp-bigdata-b-dn105:25008,shyp-bigdata-b-dn101:25008,shyp-bigdata-b-dn099:25008,shyp-bigdata-b-dn098:25008,shyp-bigdata-b-dn096:25008,shyp-bigdata-b-dn102:25008,shyp-bigdata-b-dn095:25008,shyp-bigdata-b-dn104:25008,shyp-bigdata-b-dn086:25008,shyp-bigdata-b-dn085:25008,shyp-bigdata-b-dn084:25008,shyp-bigdata-b-dn087:25008,shyp-bigdata-b-dn083:25008,shyp-bigdata-b-dn082:25008,shyp-bigdata-b-dn088:25008,shyp-bigdata-b-dn081:25008,shyp-bigdata-b-dn089:25008,shyp-bigdata-b-dn093:25008,shyp-bigdata-b-dn135:25008,shyp-bigdata-b-dn076:25008,shyp-bigdata-b-dn077:25008,shyp-bigdata-b-dn078:25008,shyp-bigdata-b-dn075:25008,shyp-bigdata-b-dn074:25008,shyp-bigdata-b-dn062:25008,shyp-bigdata-b-dn061:25008,shyp-bigdata-b-dn060:25008,shyp-bigdata-b-dn058:25008,shyp-bigdata-b-dn057:25008</value>
</property>
<property>
<name>dfs.namenode.retrycache.expirytime.millis</name>
<value>600000</value>
</property>
<property>
<name>dfs.ha.fencing.ssh.connect-timeout</name>
<value>10000</value>
</property>
<property>
<name>dfs.namenode.fs-limits.max-component-length</name>
<value>7999</value>
</property>
<property>
<name>dfs.namenode.service.handler.count</name>
<value>10</value>
</property>
<property>
<name>dfs.ha.fencing.methods</name>
<value>shell(/bin/true)</value>
</property>
<property>
<name>dfs.namenode.enable.retrycache</name>
<value>true</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
<value>DEFAULT</value>
</property>
<property>
<name>ipc.25000.faircallqueue.decay-scheduler.decay-factor</name>
<value>0.5</value>
</property>
<property>
<name>dfs.ha.tail-edits.period</name>
<value>60</value>
</property>
<property>
<name>ipc.25000.faircallqueue.decay-scheduler.period-ms</name>
<value>5000</value>
</property>
<property>
<name>dfs.ha.namenodes.hacluster</name>
<value>7764,7765</value>
</property>
<property>
<name>dfs.namenode.https-address.hacluster.7765</name>
<value>shyp-bigdata-b-cn07:25003</value>
</property>
<property>
<name>dfs.namenode.replication.considerLoad.io-load</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.startup.delay.block.deletion.sec</name>
<value>3600</value>
</property>
<property>
<name>dfs.namenode.https-address.hacluster.7764</name>
<value>shyp-bigdata-b-cn06:25003</value>
</property>
<property>
<name>dfs.client.socketcache.capacity</name>
<value>16</value>
</property>
<property>
<name>dfs.namenode.rpc-address.hacluster.7764</name>
<value>shyp-bigdata-b-cn06:25000</value>
</property>
<property>
<name>dfs.namenode.shared.edits.dir</name>
<value>qjournal://${dfs.namenode.journalnode}/hacluster</value>
</property>
<property>
<name>dfs.namenode.edits.dir</name>
<value>/srv/BigData/namenode</value>
</property>
<property>
<name>dfs.namenode.rpc-address.hacluster.7765</name>
<value>shyp-bigdata-b-cn07:25000</value>
</property>
<property>
<name>dfs.image.loader.inode.partition</name>
<value>1048576</value>
</property>
<property>
<name>dfs.nodelabel.enabled</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.rpc.port</name>
<value>25000</value>
</property>
<property>
<name>dfs.namenode.name.dir.restore</name>
<value>false</value>
</property>
<property>
<name>dfs.nodetag.nextpolicy</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault</value>
</property>
<property>
<name>dfs.datanode.lifeline.interval.seconds</name>
<value></value>
</property>
<property>
<name>dfs.support.append</name>
<value>true</value>
</property>
<property>
<name>dfs.balancer.auto.cron.expression</name>
<value>0 1 * * 6</value>
</property>
<property>
<name>dfs.datanode.socket.reuse.keepalive</name>
<value>4000</value>
</property>
<property>
<name>dfs.namenode.checkpoint.period</name>
<value>3600</value>
</property>
<property>
<name>dfs.ha.automatic-failover.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.nodetag.host2tags.file</name>
<value>/opt/client/HDFS/hadoop/etc/hadoop/host2tags</value>
</property>
<property>
<name>dfs.nodetag.path2expression.file</name>
<value>/opt/client/HDFS/hadoop/etc/hadoop/path2expression</value>
</property>
</configuration>