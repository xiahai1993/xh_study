<?xml version="1.0" encoding="UTF-8"?>
<configuration>
<property>
<name>hive.metastore.db.ssl.enabled</name>
<value>false</value>
</property>
<property>
<name>spark.thriftserver.retry.wait.time</name>
<value>10</value>
</property>
<property>
<name>hive.security.authenticator.manager</name>
<value>org.apache.hadoop.hive.ql.security.SessionStateUserGroupAuthenticator</value>
</property>
<property>
<name>hive.metastore.sasl.enabled</name>
<value>true</value>
</property>
<property>
<name>hive.security.authorization.manager</name>
<value>org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory</value>
</property>
<property>
<name>hive.server2.authentication</name>
<value>KERBEROS</value>
</property>
<property>
<name>hive.metastore.warehouse.dir</name>
<value>/user/hive/warehouse</value>
</property>
<property>
<name>hive.metastore.thrift.sasl.qop</name>
<value>auth-conf</value>
</property>
<property>
<name>hive.metastore.uris</name>
<value>thrift://10.11.42.27:21088,thrift://10.11.42.26:21088</value>
</property>
<property>
<name>hive.server2.authentication.kerberos.principal</name>
<value>spark/hadoop.hadoop_b.com@HADOOP_B.COM</value>
</property>
<property>
<name>spark.thriftserver.retry.times</name>
<value>5</value>
</property>
<property>
<name>hive.metastore.token.signature</name>
<value>HiveServer2ImpersonationToken</value>
</property>
<property>
<name>hive.metastore.rdb.password.decode.enable</name>
<value>true</value>
</property>
<property>
<name>spark.thriftserver.ha.enabled</name>
<value>true</value>
</property>
<property>
<name>hive.metastore.kerberos.principal</name>
<value>hive/hadoop.hadoop_b.com@HADOOP_B.COM</value>
</property>
<property>
<name>spark.deploy.zookeeper.url</name>
<value>10.11.42.27:24002,10.11.42.24:24002,10.11.42.26:24002,10.11.42.23:24002,10.11.42.25:24002</value>
</property>
<property>
<name>hive.security.authorization.enabled</name>
<value>true</value>
</property>
<property>
<name>hive.server2.thrift.sasl.qop</name>
<value>auth-conf</value>
</property>
<property>
<name>hive.security.authorization.sqlstd.confwhitelist.append</name>
<value>hbase\.compact\.index\.combine|hbase\.composite\.key\.factory|hive\.map\.aggr\.hash\.percentmemory|hive\.map\.aggr\.hash\.force\.flush\.memory\.threshold|hive\.map\.aggr\.hash\.min\.reduction|hive\.multigroupby\.singlereducer|hive\.map\.groupby\.sorted|hive\.map\.groupby\.sorted\.testmode|hive\.exec\.mode\.splits\.local\.auto|mapreduce\.framework\.name|hive\.aux\.jars\.path|hive\.smalltable\.filesize|hive\.mapred\.map\.tasks\.speculative\.execution|hive\.mapred\.reduce\.tasks\.speculative\.execution|mapreduce\.job\.ubertask\.enable|mapreduce\.job\.ubertask\.maxmaps|mapreduce\.job\.ubertask\.maxreduces|hive\.textinput\.record\.delimiter|dfs\.block\.size|mapreduce\.input\.fileinputformat\.split\.maxsize|mapreduce\.task\.io\.sort\.mb|hive\.input\.format|orc\.output\.codec|hive\.exec\.max\.dynamic\.partitions|inner\.client\.marker</value>
</property>
<property>
<name>hive.authorization.msck.enabled</name>
<value>true</value>
</property>
<property>
<name>hive.security.authorization.createtable.owner.grants</name>
<value>ALL</value>
</property>
<property>
<name>hive.server2.thrift.port</name>
<value>23040</value>
</property>
<property>
<name>hive.server2.enable.doAs</name>
<value>false</value>
</property>
<property>
<name>hive.exec.scratchdir</name>
<value>/tmp/sparkhive-scratch</value>
</property>
<property>
<name>spark.thriftserver.zookeeper.dir</name>
<value>/thriftserver</value>
</property>
<property>
<name>hive.server2.thrift.bind.host</name>
<value>10.11.42.40</value>
</property>
<property>
<name>hive.added.jars.path</name>
<value>file:/opt/client/Spark/spark/lib/kryo-2.21.jar,file:/opt/client/Spark/spark/lib/joda-time-2.5.jar,file:/opt/client/Spark/spark/lib/libthrift-0.9.3.jar,file:/opt/client/Spark/spark/lib/javolution-5.5.1.jar,file:/opt/client/Spark/spark/lib/JavaEWAH-0.3.2.jar</value>
</property>
</configuration>